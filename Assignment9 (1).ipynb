{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b2f9c0a-4766-402a-b177-deaef442e4c2",
   "metadata": {},
   "source": [
    "TOPIC: Docker\n",
    "1. Scenario: You are building a microservices-based application using Docker. Design a Docker Compose file that sets up three containers: a web server container, a database container, and a cache container. Ensure that the containers can communicate with each other properly.\n",
    "2. Scenario: You want to scale your Docker containers dynamically based on the incoming traffic. Write a Python script that utilizes Docker SDK to monitor the CPU usage of a container and automatically scales the number of replicas based on a threshold.\n",
    "3. Scenario: You have a Docker image stored on a private registry. Develop a script in Bash that authenticates with the registry, pulls the latest version of the image, and runs a container based on that image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dab43e9-c867-41b7-be31-401d46b0586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing a Docker Compose File for Microservices:\n",
    "\n",
    "version: '3'\n",
    "services:\n",
    "  webserver:\n",
    "    image: your-webserver-image\n",
    "    ports:\n",
    "      - 80:80\n",
    "    depends_on:\n",
    "      - database\n",
    "      - cache\n",
    "\n",
    "  database:\n",
    "    image: your-database-image\n",
    "    ports:\n",
    "      - 3306:3306\n",
    "\n",
    "  cache:\n",
    "    image: your-cache-image\n",
    "    ports:\n",
    "      - 6379:6379\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad4e692-b722-4608-ac29-7d52a491120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "import time\n",
    "\n",
    "def monitor_cpu_usage(container_id):\n",
    "    client = docker.from_env()\n",
    "    container = client.containers.get(container_id)\n",
    "    while True:\n",
    "        stats = container.stats(stream=False)\n",
    "        cpu_usage = stats['cpu_stats']['cpu_usage']['total_usage']\n",
    "        cpu_limit = stats['cpu_stats']['cpu_usage']['max_usage']\n",
    "        cpu_percentage = (cpu_usage / cpu_limit) * 100\n",
    "\n",
    "        print(f\"CPU Usage: {cpu_percentage}%\")\n",
    "\n",
    "        if cpu_percentage > 80:\n",
    "            scale_up()  # Call the function to scale up the number of replicas\n",
    "        elif cpu_percentage < 50:\n",
    "            scale_down()  # Call the function to scale down the number of replicas\n",
    "\n",
    "        time.sleep(10)  # Monitor every 10 seconds\n",
    "\n",
    "def scale_up():\n",
    "    # Code to scale up the number of replicas\n",
    "    # Replace this with your actual scaling logic\n",
    "\n",
    "def scale_down():\n",
    "    # Code to scale down the number of replicas\n",
    "    # Replace this with your actual scaling logic\n",
    "\n",
    "# Example usage\n",
    "container_id = 'your-container-id'  # Replace with the ID of your Docker container\n",
    "monitor_cpu_usage(container_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dba1f4-e5f3-4871-99c3-5231261ed06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "REGISTRY_URL=\"your-registry-url\"\n",
    "IMAGE_NAME=\"your-image-name\"\n",
    "CONTAINER_NAME=\"your-container-name\"\n",
    "\n",
    "# Authenticate with the private registry\n",
    "docker login -u <username> -p <password> $REGISTRY_URL\n",
    "\n",
    "# Pull the latest version of the image\n",
    "docker pull $REGISTRY_URL/$IMAGE_NAME:latest\n",
    "\n",
    "# Run a container based on the image\n",
    "docker run -d --name $CONTAINER_NAME $REGISTRY_URL/$IMAGE_NAME:latest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd4cf8-679e-4b8a-951f-4127f26f886d",
   "metadata": {},
   "source": [
    "\n",
    "TOPIC: Airflow\n",
    "1. Scenario: You have a data pipeline that requires executing a shell command as part of a task. Create an Airflow DAG that includes a BashOperator to execute a specific shell command.\n",
    "2. Scenario: You want to create dynamic tasks in Airflow based on a list of inputs. Design an Airflow DAG that generates tasks dynamically using PythonOperator, where each task processes an element from the input list.\n",
    "3. Scenario: You need to set up a complex task dependency in Airflow, where Task B should start only if Task A has successfully completed. Implement this dependency using the \"TriggerDagRunOperator\" in Airflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b71cb0-5113-4d31-a4f6-65d2231ceae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "from datetime import datetime\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'start_date': datetime(2023, 1, 1),\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'shell_command_dag',\n",
    "    default_args=default_args,\n",
    "    schedule_interval='0 0 * * *'  # Run once daily at midnight\n",
    ")\n",
    "\n",
    "bash_task = BashOperator(\n",
    "    task_id='execute_shell_command',\n",
    "    bash_command='echo \"Hello, World!\"',  # Replace with your shell command\n",
    "    dag=dag\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06afa2f6-2056-47a3-b011-ed8c56c5acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'start_date': datetime(2023, 1, 1),\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'dynamic_tasks_dag',\n",
    "    default_args=default_args,\n",
    "    schedule_interval=None  # Disable automatic scheduling\n",
    ")\n",
    "\n",
    "def process_input(input_value):\n",
    "    # Code to process the input value\n",
    "    print(f\"Processing input: {input_value}\")\n",
    "\n",
    "input_list = [1, 2, 3, 4, 5]  # Replace with your list of inputs\n",
    "\n",
    "for input_value in input_list:\n",
    "    task_id = f'process_input_{input_value}'\n",
    "    task = PythonOperator(\n",
    "        task_id=task_id,\n",
    "        python_callable=process_input,\n",
    "        op_kwargs={'input_value': input_value},\n",
    "        dag=dag\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a1a619-7c21-43e1-b1aa-dacd2d16092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.dagrun_operator import TriggerDagRunOperator\n",
    "from datetime import datetime\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'start_date': datetime(2023, 1, 1),\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'complex_dependency_dag',\n",
    "    default_args=default_args,\n",
    "    schedule_interval=None  # Disable automatic scheduling\n",
    ")\n",
    "\n",
    "def dummy_function():\n",
    "    pass\n",
    "\n",
    "trigger_task = TriggerDagRunOperator(\n",
    "    task_id='trigger_task',\n",
    "    trigger_dag_id='subdag_id',\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "dummy_task = PythonOperator(\n",
    "    task_id='dummy_task',\n",
    "    python_callable=dummy_function,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "trigger_task >> dummy_task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913e6ea7-c260-4884-97f4-5c72e6c87ff4",
   "metadata": {},
   "source": [
    "\n",
    "TOPIC: Sqoop\n",
    "1. Scenario: You want to import data from an Oracle database into Hadoop using Sqoop, but you only need to import specific columns from a specific table. Write a Sqoop command that performs the import, including the necessary arguments for column selection and table mapping.\n",
    "2. Scenario: You have a requirement to perform an incremental import of data from a MySQL database into Hadoop using Sqoop. Design a Sqoop command that imports only the new or updated records since the last import.\n",
    "3. Scenario: You need to export data from Hadoop to a Microsoft SQL Server database using Sqoop. Develop a Sqoop command that exports the data, considering factors like database connection details, table mapping, and appropriate data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809e1571-50f3-4794-8b16-a6955db3f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqoop import \\\n",
    "  --connect jdbc:oracle:thin:@<host>:<port>:<database> \\\n",
    "  --username <username> \\\n",
    "  --password <password> \\\n",
    "  --table <table_name> \\\n",
    "  --columns \"<column1>,<column2>,<column3>\" \\\n",
    "  --target-dir <target_directory>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ee55a-0fb0-4ffd-8230-292dbd606feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqoop import \\\n",
    "  --connect jdbc:mysql://<host>:<port>/<database> \\\n",
    "  --username <username> \\\n",
    "  --password <password> \\\n",
    "  --table <table_name> \\\n",
    "  --incremental append \\\n",
    "  --check-column <column_name> \\\n",
    "  --last-value <last_imported_value> \\\n",
    "  --target-dir <target_directory>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db0eee-b279-4333-8c84-1b50456660d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqoop export \\\n",
    "  --connect \"jdbc:sqlserver://<server_name>:<port>;database=<database_name>\" \\\n",
    "  --username <username> \\\n",
    "  --password <password> \\\n",
    "  --table <table_name> \\\n",
    "  --export-dir <source_directory> \\\n",
    "  --input-fields-terminated-by ',' \\\n",
    "  --input-lines-terminated-by '\\n'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
